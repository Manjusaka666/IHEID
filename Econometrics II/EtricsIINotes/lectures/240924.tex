\section{Some Basic Concepts}

\begin{definition}
    \textbf{\textcolor{blue}{Null Hypothesis}}
    
    The null hypothesis $\mathcal{H}_0$ is the set $\theta = \theta_0$ or $\beta \in \mathcal{B}_0$.
    
    Or, we denote it as:
    \[ \mathcal{H}_0 : \theta \in \Theta_0 \]
    For econometrics, we usually set $\mathcal{H}_0 : \beta = 0$.
\end{definition}

\begin{definition}
    \textbf{\textcolor{blue}{Alternative Hypothesis}}
    
    The alternative hypothesis $\mathcal{H}_1$ is the set $\{ \theta \in \Theta : \theta \neq \theta_0 \}$ or $\{ \beta \in \mathcal{B} : \beta \notin \mathcal{B}_0 \}$.
    
    Or, we denote it as:
    \[ \mathcal{H}_1 : \theta \in \Theta_1 \]
    For econometrics, we usually set $\mathcal{H}_1 : \beta \neq 0$. Often $\Theta_1$ is the complement of $\Theta_0$.
\end{definition}

\begin{note}
    Point estimator of $\mathbf{1} \{ \theta \in \Theta_0 \}$ (if $\theta \in \Theta_0$, the function equals 1).
\end{note}

\begin{center}
    \begin{tabular}{|c|c|c|}
        \hline
        & $\mathcal{H}_0$ is true & $\mathcal{H}_0$ is false\\
        \hline
        Accept $\mathcal{H}_0$ & $\checkmark$: $1 - \alpha$ & $\times$: $1 - \beta$\\
        \hline
        Reject $\mathcal{H}_0$ & $\times$: $\alpha$ & $\checkmark$: $\beta$\\
        \hline
    \end{tabular}
\end{center}

$\alpha$ is the Type I error, $1 - \beta$ is the Type II error.

\begin{definition}
    A hypothesis test $\varphi \in \{0, 1\}$ is a rule that specifies when we reject and when we accept (do not reject) $\mathcal{H}_0$, with $\varphi = 0$ indicating rejection.
\end{definition}

\begin{definition}
    \textbf{Power Function}
    \[ \beta (\theta) = \mathbb{P} [\text{rejecting} | \theta \text{ is} \text{ true}] = \mathbb{P} [\varphi = 0 | \theta] \]
\end{definition}

\begin{definition}
    \textbf{Size of a test}
    
    The size of a test is $\alpha$ if $\underset{\theta \in \Theta_0}{\sup} \beta (\theta_0) = \alpha$, $\alpha \in (0, 1)$.
\end{definition}

\textit{Generic form:}
\[ \varphi (x ; \alpha) = \mathbf{1} \{ T (x) < c_{\alpha} \} \]

\section{T-test}

\begin{definition}
    Suppose $\hat{\theta} | \theta \sim N (\theta, v^2)$, and we are testing a point hypothesis $\mathcal{H}_0 : \theta = \theta_0$. Under the alternative $\mathcal{H}_1 : \theta \neq \theta_0$, the two-sided t-test is
    \[ \varphi_t (x) = \mathbf{1} \left\{ \left| \frac{\hat{\theta} - \theta_0}{v} \right| < c \right\} \]
\end{definition}

\begin{note}
    The test-statistic $T (X) = \left| \frac{\hat{\theta} - \theta_0}{v} \right|$ is a function of data $X$ because our estimator $\theta$, $\hat{\theta}$, is a function of $X$.
\end{note}

\begin{eg}
    Let $X | \theta \sim N (\theta, v^2)$, under $\mathcal{H}_0 : \hat{\theta} \sim N (\theta_0, v^2)$ $\rightarrow$ $\frac{\hat{\theta} - \theta_0}{v} \sim N (0, 1)$
\end{eg}

\includegraphics[width=\textwidth]{t-test.pdf}

\begin{align*}
    \beta (\theta) & = \mathbb{P} [\text{rejecting} | \theta \text{ is} \text{ true}]\\
    & = \mathbb{P} [\varphi = 0 | \theta]\\
    & = \mathbb{P} [T (X) > c_{\alpha} | \theta]\\
    & = \mathbb{P} \left[ \left| \frac{\hat{\theta} - \theta_0}{v} \right| > c_{\alpha} | \theta \right]\\
    & = 1 - \mathbb{P} \left[ \left| \frac{\hat{\theta} - \theta_0}{v} \right| \leq c_{\alpha} | \theta \right]\\
    & = 1 - \mathbb{P} \left[ - c_{\alpha} \leq \frac{\hat{\theta} - \theta_0}{v} \sim N (0, 1) \leq c_{\alpha} | \theta \right]\\
    & = 1 - \left( \mathbb{P} \left[ \frac{\hat{\theta} - \theta_0}{v} \leq c_{\alpha} | \theta \right] - \mathbb{P} \left[ \frac{\hat{\theta} - \theta_0}{v} \leq - c_{\alpha} | \theta \right] \right)\\
    & = 1 - [\Phi (c_{\alpha}) - \Phi (- c_{\alpha})]\\
    & = 1 - [\Phi (c_{\alpha}) - (1 - \Phi (c_{\alpha}))]\\
    & = 2 - 2 \Phi (c_{\alpha})\\
    & = \alpha
\end{align*}

Under $\alpha = 0.05$, we get $c_{\alpha} = 1.64$, $\alpha = 0.1$, we get
$c_{\alpha} = 1.96$.

To compute the power of this test, we need to think about what happens if
$\mathcal{H}_0$ is false. Assuming that $\tilde{\theta}$ is the true value of
$\theta$.

\begin{align*}
  \beta (\tilde{\theta}) & = \mathbb{P} [\text{rejecting} |
  \tilde{\theta} \text{ is true}]\\
  & = \mathbb{P} [\varphi = 0 | \tilde{\theta}]\\
  & = \mathbb{P} [T (X) > c_{\alpha} | \tilde{\theta}]\\
  & = \mathbb{P} \left[ \left| \frac{\hat{\theta} - \theta_0}{v} \right| >
  c_{\alpha} | \tilde{\theta} \right]
\end{align*}

To find this, under $\tilde{\theta}$ is true, $\tilde{\theta} \sim N
(\tilde{\theta}, v^2)$, $\hat{\theta} - \tilde{\theta} \sim N (0, v^2)$,
$\hat{\theta} - \theta_0 \sim N (\tilde{\theta} - \theta_0, v^2)$,
$\frac{\hat{\theta} - \theta_0}{v} \sim N (\tilde{\theta} - \theta_0, 1)$,
$\frac{\hat{\theta} - \theta_0}{v} - (\tilde{\theta} - \theta_0) \sim N (0,
1)$

So,
\begin{align*}
  \beta (\tilde{\theta}) & = \mathbb{P} \left[ \left| \frac{\hat{\theta} -
  \theta_0}{v} \right| > c_{\alpha} | \tilde{\theta}
  \right]\\
  & = 1 - \mathbb{P} \left[ \left| \frac{\hat{\theta} - \theta_0}{v}
  \right| \leq c_{\alpha} | \theta \right]\\
  & = 1 - \mathbb{P} \left[ - c_{\alpha} \leq \frac{\hat{\theta} -
  \theta_0}{v} \leq c_{\alpha} | \theta \right]\\
  & = 1 - \mathbb{P} [- c_{\alpha} - (\tilde{\theta} - \theta_0) \leq z
  \sim N (0, 1) \leq c_{\alpha} - (\tilde{\theta} - \theta_0)]\\
  & = 1 - (\Phi [c_{\alpha} - (\tilde{\theta} - \theta_0)] - \Phi [-
  c_{\alpha} - (\tilde{\theta} - \theta_0)])
\end{align*}

The higher the probability of wrongly accepting (or failing to reject)
$\mathcal{H}_0$. It is common to be rather conservative (i.e. erring on the
side of not rejecting $\mathcal{H}_0$) and report test results for sizes of
10\%, 5\% and 1\%.

\section{Likelihood Ratio Test}

\begin{definition}
  \[ \varphi_{\text{LR}} (x) = \mathbf{1} \left\{ \frac{\underset{\theta \in
     \Theta_1}{\sup} p (x | \theta)}{\underset{\theta \in
     \Theta_0}{\sup} p (x | \theta)} < c_{\alpha} \right\},
     T_{\text{LR}} (X) = \frac{\underset{\theta \in \Theta_1}{\sup} p (x |
  \theta)}{\underset{\theta \in \Theta_0}{\sup} p (x | \theta)}.\]
\end{definition}

So, if there are points in $\Theta_0$ for which observed $x$ is more likely
than points in $\Theta_1$, the ratio is small --- the test is likely to accept
$\mathcal{H}_0$.

Under $\mathcal{H}_0 : \theta = \theta_0$ and the alternative $\mathcal{H}_1 :
\theta \neq \theta_0$,
\[ \varphi_{\text{LR}} (x) = \mathbf{1} \left\{ \frac{p (x |
   \hat{\theta}_{\text{ML}})}{p (x | \theta_0)} < c \right\} \]

\begin{eg}
  $\{ x_i \}_{i = 1}^n$, $x_i | \theta \sim N (\theta, 1)$,
  \[ p (x | \theta) = \prod_i p (x_i | \theta) = (2
     \pi)^{- \frac{1}{2}} \exp \left\{ - \frac{1}{2} (x - \theta)^2 \right\}
  \]
  if $n = 1$. As $x = \hat{\theta}$, $p (x | \hat{\theta}) = (2
  \pi)^{- \frac{1}{2}}$
  \[ T (x) = \frac{p (x | \hat{\theta}_{\text{ML}})}{p (x |
     \theta_0)} = \frac{(2 \pi)^{- \frac{1}{2}} \exp \left\{ -
     \frac{1}{2} (x - \hat{\theta})^2 \right\}}{(2 \pi)^{- \frac{1}{2}} \exp
     \left\{ - \frac{1}{2} (x - \theta_0)^2 \right\}} = \exp \left\{
     \frac{1}{2} (x - \theta_0)^2 \right\} \]
  as $x = \hat{\theta}$.
  \[ \varphi_{\text{LR}} = \mathbf{1} \left\{ \exp \left\{ \frac{1}{2} (x -
     \theta_0)^2 \right\} < c_{\alpha} \right\} \]
\end{eg}

\begin{align*}
  \alpha & = \mathbb{P} \{ \text{Reject} | \theta_0 \text{ is}
  \text{ actually true} \}\\
  & = \mathbb{P} \left\{ \exp \left\{ \frac{1}{2} (x - \theta_0)^2 \right\}
  \geq c_{\alpha} | \theta_0 \right\}\\
  & = \mathbb{P} \{ (x - \theta_0)^2 \geq 2 \log c_{\alpha} |
  \theta_0 \}\\
  & = 1 - \mathbb{P} \left\{ (x - \theta_0)^2 <
  2 \log c_{\alpha} | \theta_0 \right\}
\end{align*}

If $x \sim N (\theta_0, 1)$, $(x - \theta_0)^2 \sim \chi_{1}^2$

\includegraphics[width=\textwidth]{Chi-2.pdf}

\begin{note}
  \textbf{\textcolor{red}{Uniformly most powerful test}} Highest probability
  of rejection, of wrong acceptance.
\end{note}

\[ \varphi (x) = \mathbf{1} \{ T (x) < c_{\alpha} \} \]
\[ \alpha = \mathbb{P} \{ T (x) > c_{\alpha} | \theta_0 \} 
   (\text{reject rule}) \]

\subsection{Numerical Hypothesis Testing}

\begin{algorithm}[H]
  \caption{Numerical Hypothesis Testing}
  \SetAlgoLined
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}
  
  \Input{Distribution $N(\theta_0, 1)$, sample size $M$, significance level $\alpha$}
  \Output{Decision to accept or reject $H_0$}
  
  \For{$m = 1$ \KwTo $M$}{
      Draw $x^m \sim N(\theta_0, 1)$\;
      Compute $T(x^m)$\;
  }
  
  Sort $\{T(x^m)\}_{m=1}^M$ in ascending order\;
  Set $c_\alpha$ to the $100(1 - \alpha)$ quantile of $\{T(x^m)\}_{m=1}^M$\;
  
  Compute $T(x)$ for your observed realization $x$\;
  \eIf{$T(x) \leq c_\alpha$}{
      Accept $H_0$\;
  }{
      Reject $H_0$\;
  }
\end{algorithm}

Small $p\text{-value}$ means $\mathcal{H}_0$ is likely to be rejected,
larger $p\text{-value}$ means it's likely to be true.

\section{Coverage Sets}

\subsection{Frequentist Confidence Sets}

A confidence set $C (X) \subseteq \Theta$ is a (random) set that should cover
the true $\theta$ with a prespecified probability:
\[ \underset{\theta \in \Theta}{\inf} \mathbb{P} [\theta \in C (X) |
   \theta] = 1 - \alpha \]
\[ C (x) = \{ \theta_0 \in \Theta : \varphi (x ; \theta_0) = 1 \} \]
contains all the values of $\theta_0$ that we would accept.

Consider $\mathcal{H}_0 : \theta = \theta_0$ vs. $\mathcal{H}_1 : \theta \neq
\theta_0$, $\varphi_{\alpha} (x) = \mathbf{1} \{ T (x) < c_{\alpha ; \theta_0}
\}$.

\begin{eg}
  T-test: $T (x) = \left| \frac{\hat{\theta} - \theta_0}{v} \right|$
  $\Rightarrow$ $\varphi \{ x ; \theta_0, \alpha \} = \mathbf{1} \{ T (x) < c
  \}$
  \begin{align*}
    C (x) & = \{ \theta_0 \in \Theta, \varphi \{ x ; \theta_0, \alpha \} = 1
    \}\\
    & = \left\{ \theta_0 \in \Theta, \left| \frac{\hat{\theta} -
    \theta_0}{v} \right| < c \right\}\\
    & = \left\{ \theta_0 \in \Theta, - c < \frac{\hat{\theta} -
    \theta_0}{v} < c \right\}\\
    & = \{ \theta_0 \in \Theta, - c v + \hat{\theta} < \theta_0 < c v +
    \hat{\theta} \}
  \end{align*}
\end{eg}

\begin{eg}
  LR-test: $\varphi (x ; \theta_0, \alpha) = \mathbf{1} \{ (x - \theta_0)^2 <
  \tilde{c_{\alpha}} \}$
  \begin{align*}
    C (x) & = \{ \theta_0 \in \Theta, \varphi \{ x ; \theta_0, \alpha \} = 1
    \}\\
    & = \{ \theta_0 \in \Theta, (x - \theta_0)^2 < \tilde{c_{\alpha}}
    \}\\
    & = \left\{ \theta_0 \in \Theta, - \sqrt{\tilde{c_{\alpha}}} < x -
    \theta_0 < \sqrt{\tilde{c_{\alpha}}} \right\}\\
    & = \left\{ \theta_0 \in \Theta, x - \sqrt{\tilde{c_{\alpha}}} <
    \theta_0 < x + \sqrt{\tilde{c_{\alpha}}} \right\}
  \end{align*}
\end{eg}

\subsection{Numerical Confidence Set Construction}

\begin{algorithm}[H]
  \caption{Numerical Confidence Set Construction}
  \SetAlgoLined
  
  \KwData{Choose a grid $\mathcal{T}$ of values for $\theta_0$}
  \For{each $\theta_0 \in \mathcal{T}$}{
    \For{$m = 1$ \KwTo $M$}{
        Draw $x^m \sim N(\theta_0, 1)$ \tcp*{Distribution of $X$ under $H_0 : \theta = \theta_0$}
        Compute $T(x^m, \theta_0)$\;
    }

    Get the critical value $c_\alpha(\theta_0)$ as the $(1-\alpha)$th quantile of $\{T(x^m, \theta_0)\}_{m=1}^M$\;
    Compute $T(x; \theta_0)$ for observed $x$\;
    
    \eIf{$T(x; \theta_0) \leq c_\alpha(\theta_0)$}{
        $\theta_0 \in C(x)$\;
    }{
        $\theta_0 \not\in C(x)$\;
    }
  }
\end{algorithm}