\section{Incidental Parameters Problem}

\subsection{Consistency}
$i=1: n$, $t=1: T$, $z_{it} $
\begin{align*}
  y_{it} &= \alpha +x_{it}^{\prime} \beta +u_{it} \\
  &= \tilde{x}_{it}^{\prime} \tilde{\beta} + u_{it} \\
  \tilde{x}_{it} &= \begin{bmatrix}
    1 \\
    x_{it}
  \end{bmatrix} \\
  \tilde{\beta} &= \begin{bmatrix}
    \alpha \\
    \beta
  \end{bmatrix}
\end{align*}

Then, 
\[ 
\underset{T\times 1}{y_i} = \underset{T \times K}{\tilde{x}_i} \underset{K \times 1}{\tilde{\beta}} + \underset{T \times 1}{u_i}
\]
\[
\underset{\tilde{\beta}}{\min} \sum_i \sum_t u_{it}^2 = \underset{\beta}{\min} \sum_i u_i^{\prime} u_i = \underset{\beta}{\min} (y_i - \tilde{x}_i \tilde{\beta})^{\prime} (y_i - \tilde{x}_i \tilde{\beta})
\]
The FOC of this equation is:
\begin{align*}
  \sum_i -\tilde{x}_i^{\prime} (y_i - \tilde{x}_i \tilde{\beta}) &= 0 \\
  \left(\sum_i \tilde{x}_i^{\prime} \tilde{x}_i \right) \tilde{\beta} &= \sum_i \tilde{x}_i^{\prime} y_i \\
  \hat{\tilde{\beta}} &= \left(\sum_i \tilde{x}_i^{\prime} \tilde{x}_i \right)^{-1} \sum_i \tilde{x}_i^{\prime} y_i \\
  &= \left(\sum_i \sum_t \tilde{x}_{it} \tilde{x}_{it}^{\prime} \right)^{-1} \left( \sum_i \sum_t \tilde{x}_{it} y_{it} \right) \\
  &= \tilde{\beta} + \left(\frac{1}{n} \sum_i \sum_t \tilde{x}_{it} \tilde{x}_{it}^{\prime} \right)^{-1} \left( \sum_i \sum_t \tilde{x}_{it} u_{it} \right) \\
  & \overset{p}{\rightarrow} \tilde{\beta} + \mathbb{E}\left[\sum_t \tilde{x}_{it} \tilde{x}_{it}^{\prime} \right] \mathbb{E}\left[\sum_t \tilde{x}_{it} u_{it} \right] \\
  &= \tilde{\beta}
\end{align*}

\subsection{Asymptotic Normality}

From the analysis of consistency, we know that:
\[ 
\hat{\tilde{\beta}} = \left(\sum_i \tilde{x}_i^{\prime} \tilde{x}_i \right)^{-1} \sum_i \tilde{x}_i^{\prime} y_i
\]
Hence:
\begin{align*}
    \sqrt{n} (\hat{\tilde{\beta}} - \tilde{\beta}) &= \left(\frac{1}{n} \sum_i \tilde{x}_i^{\prime} \tilde{x}_i \right)^{-1} \left(\frac{1}{\sqrt{n} } \sum_i \tilde{x}_i^{\prime} u_i \right) \\
    & \overset{p}{\rightarrow}\mathbb{E}[\tilde{x}_i^{\prime} \tilde{x}_i]^{-1} \overset{d}{\rightarrow} \mathcal{N}\left(0, \mathbb{E}\left[\left(\tilde{x}_i^{\prime} u_i\right) \left(\tilde{x}_i^{\prime} u_i\right)^{\prime} \right] \right)\\
    & \overset{d}{\rightarrow} \mathcal{N} \left(0, \mathbb{E}\left[\tilde{x}_i^{\prime} \tilde{x}_i \right]^{-1} \mathbb{E}\left[\tilde{x}_i^{\prime} u_i u_i^{\prime} \tilde{x}_i \right] \mathbb{E}\left[\tilde{x}_i^{\prime} \tilde{x}_i \right] \right)
\end{align*}

For $y_{it} = \alpha_i + x_{it}^{\prime} \beta + u_{it} $,

Under $T=1$, we run $y_i = \beta_0 + x_i^{\prime} \beta + v_i$, 
where $v_u = u_i + \underset{\tilde{\alpha}_i}{\underbrace{\alpha_i - \beta_0}}$
and $\mathbb{E}[v_i] = 0$.

Under $T>1$, we run:
\begin{align*}
    y_i &= x_i^{\prime} \beta  + \sum_{j=1}^{n} \alpha_j \mathbf{1}\{i=j\} + u_{it} \\
    &= \tilde{x}_{it}^{\prime} \tilde{\beta} + u_{it} \\
    \tilde{x}_{it} &= \begin{bmatrix}
      x_{it} \\
      \mathbf{1}\{i=1\} \\
      \mathbf{1}\{i=2\} \\
      \vdots \\
      \mathbf{1}\{i=n\}
    \end{bmatrix}, \quad
    \tilde{\beta} = \begin{bmatrix}
      \beta \\
      \alpha_1 \\
      \alpha_2 \\
      \vdots \\
      \alpha_n
    \end{bmatrix}
\end{align*}

\section{Random Effects}
We put $\alpha_i$ in error terms



\section{Fixed Effects}
We transform equation to get rid of $\alpha_i$.




\section{Correlated Random Effects}
