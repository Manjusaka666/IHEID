Analysis started at: 2026-01-24 12:40:58 


═══════════════════════════════════════════════════
  PHASE 1: ENVIRONMENT SETUP
═══════════════════════════════════════════════════

=== Initializing R-Julia Hybrid Environment ===

✓ CRAN mirror set to https://cloud.r-project.org
Step 1: Loading R packages...
✓ All R packages loaded successfully.

Step 2: Initializing Julia via JuliaCall...
✓ Julia initialized successfully.
  Julia version: 1.12.2
  Julia threads: 12

Step 3: Setting up Julia packages...
  Checking DataFrames.jl...
  Checking CSV.jl...
  Checking Statistics.jl...
✓ Julia packages loaded successfully.

Step 4: Loading Julia transformation functions...
✓ Loaded julia/transformation_functions.jl

Step 5: Configuring R parallel computing...
  Total cores: 20
  Cores for parallel: 20

Step 6: Verifying directory structure...
✓ Directory structure verified.

=== Environment Setup Complete ===

Configuration Summary:
  R version: R version 4.5.2 (2025-10-31 ucrt)
  Julia version: 1.12.2
  R parallel cores: 20
  Julia threads: 12
  Working directory: E:/IHEID Economics/IHEID/Topics in Econometrics/bayesianDEestimation

✓ Ready to proceed with data acquisition and analysis.

Session info saved to results/session_info.txt


✓ Phase 1 complete.

═══════════════════════════════════════════════════
  PHASE 2: DATA ACQUISITION
═══════════════════════════════════════════════════

⚠ Raw data already exists. Skipping download.
  To force re-download, delete data/raw/ directory.

═══════════════════════════════════════════════════
  PHASE 3: DATA TRANSFORMATION
═══════════════════════════════════════════════════

=== Starting Data Transformation ===

Step 1: Loading raw data...
  Small: 420 obs × 4 vars
  Medium: 420 obs × 7 vars
  Full: 420 obs × 8 vars

Step 2: Applying transformations for BVAR estimation...
  (Log-levels for prices/quantities, levels for rates/indices)

  INDPRO: log transformation
  CPIAUCSL: log transformation
  UNRATE: level (no transformation)
  FEDFUNDS: level (no transformation)
  INDPRO: log transformation
  CPIAUCSL: log transformation
  UNRATE: level (no transformation)
  FEDFUNDS: level (no transformation)
  GS10: level (no transformation)
  SP500: log transformation
  DCOILWTICO: log transformation
  INDPRO: log transformation
  CPIAUCSL: log transformation
  UNRATE: level (no transformation)
  FEDFUNDS: level (no transformation)
  GS10: level (no transformation)
  SP500: log transformation
  DCOILWTICO: log transformation
  UMCSENT: level (no transformation)

Step 3: Creating estimation-ready matrices...
  ✓ Small estimation matrix: 420 × 4
  ✓ Medium estimation matrix: 420 × 7
  ✓ Full estimation matrix: 420 × 8

Step 4: Computing evaluation transforms using Julia...
  (Annualized growth rates for forecast evaluation)

  ✓ Evaluation transforms computed.
    Generated 12 series from small model
    Generated 21 series from medium model
    Generated 24 series from full model

Step 5: Saving processed data...
  ✓ Saved to data/processed/

=== Data Transformation Summary ===

Estimation-ready data (for BVAR input):
  - Log-levels: INDPRO, CPIAUCSL, SP500, DCOILWTICO
  - Levels: UNRATE, FEDFUNDS, GS10, UMCSENT

Evaluation transforms (for forecast accuracy):
  - *_mom: Annualized month-over-month growth (1200 × Δlog)
  - *_yoy: Year-over-year growth (100 × Δ12log)
  - *_diff: Level change (Δ1)
  - *_diff12: 12-month level change (Δ12)

✓ Data transformation complete!
Next step: Run 04_bvar_estimation.R


✓ Phase 3 complete.

═══════════════════════════════════════════════════
  PHASE 4: BVAR ESTIMATION SETUP
═══════════════════════════════════════════════════

=== Hierarchical BVAR Estimation Setup ===

Step 1: Configuring hierarchical priors...

  ✓ Hierarchical priors configured:
    - Minnesota: lambda ~ Gamma(mode=0.050, sd=0.200) with bounds [0.0010, 2.00]
    - Minnesota: alpha fixed at 3.000 (bounds [1.00, 3.00])
    - Sum-of-coefficients prior (unit-root accommodation)
    - Dummy-initial-observation prior

Step 2: Configuring MCMC parameters...
  Total draws: 10000
  Burn-in: 5000
  Effective draws: 5000

Step 3: Defining BVAR estimation function...

Step 4: Testing BVAR estimation on full sample...
  (This verifies the setup before recursive forecasting)

Data loaded. Estimating small model on full sample...
✓ Estimation successful!
Step 5: Optimal hyperparameters from test estimation:

Minnesota Prior:
  Hyperparameters auto-optimized via marginal likelihood
Minnesota Prior (Posterior Means):
  Lambda (tightness): 1.0005

Other Priors (Posterior Means):
  SOC (sum-of-coef): 0.4698
  SUR (dummy-init-obs): 0.6635

  Log-marginal likelihood (final): 3597.26
✓ Test estimation complete!
  BVAR setup verified and ready for recursive forecasting.

Step 6: Generating test forecasts (h=1,3,12)...
✓ Forecast generated.
  Forecast dimensions: 5000 horizons × 13 variables

Example: CPI forecasts (log-level):
  h=1:  4.6205
  h=3:  4.6210
  h=12: 4.6212

Step 7: Saving test estimation results...
  ✓ Saved to results/diagnostics/

=== BVAR Estimation Setup Complete ===

Key points:
  ✓ Hierarchical priors configured with automatic hyperparameter selection
  ✓ MCMC settings: 10000 draws with 5000 burn-in
  ✓ Test estimation successful on full sample
  ✓ Optimal lambda: 1.0005

✓ Phase 4 complete.

═══════════════════════════════════════════════════
  PHASE 5: RECURSIVE FORECASTING
═══════════════════════════════════════════════════

⚠ WARNING: This phase will take 30-45 minutes.
  Progress will be checkpointed every 50 origins.


=== Starting Recursive Forecasting (Parallelized) ===

  Progress will be saved with checkpoints every 50 origins.

Step 1: Loading data and configuration...
  Priors: lambda(mode=0.050, sd=0.200, min=0.001, max=2.00); alpha(mode=3.00)

  MCMC: n_draw=10000, n_burn=5000

  ✓ Data and priors loaded.

Step 2: Defining forecast origins...
  Initial training window: 1985M1 - 2000-12-31 (192 obs)
  Final forecast origin: 2019-11-30
  Number of forecast origins: 227
  Forecast period: 2001-01 to 2019-11


Step 3: Setting up parallel forecasting function...
  ✓ Forecasting function defined.

Step 4: Initializing parallel cluster...
  Cluster created with 20 workers.
  Exporting data and functions to workers...
  ✓ Cluster initialized.

╔════════════════════════════════════════════════════╗
║  RECURSIVE FORECASTING: ALL MODELS                 ║
╚════════════════════════════════════════════════════╝

═══ Forecasting SMALL Model ═══
  Variables: 4
  Forecast origins: 227
  Using 20 parallel workers

  Starting parallel forecasting...
  Progress:
    Batch 1/5: Origins 1-50... Done.
      [Checkpoint saved: 50/227 origins]
    Batch 2/5: Origins 51-100... Done.
      [Checkpoint saved: 100/227 origins]
    Batch 3/5: Origins 101-150... Done.
      [Checkpoint saved: 150/227 origins]
    Batch 4/5: Origins 151-200... Done.
      [Checkpoint saved: 200/227 origins]
    Batch 5/5: Origins 201-227... Done.
      [Checkpoint saved: 227/227 origins]

  ✓ SMALL model complete in 9.8 minutes
  Average time per origin: 2.6 seconds

═══ Forecasting MEDIUM Model ═══
  Variables: 7
  Forecast origins: 227
  Using 20 parallel workers

  Starting parallel forecasting...
  Progress:
    Batch 1/5: Origins 1-50... Done.
      [Checkpoint saved: 50/227 origins]
    Batch 2/5: Origins 51-100... Done.
      [Checkpoint saved: 100/227 origins]
    Batch 3/5: Origins 101-150... Done.
      [Checkpoint saved: 150/227 origins]
    Batch 4/5: Origins 151-200... Done.
      [Checkpoint saved: 200/227 origins]
    Batch 5/5: Origins 201-227... Done.
      [Checkpoint saved: 227/227 origins]

  ✓ MEDIUM model complete in 21.7 minutes
  Average time per origin: 5.7 seconds

═══ Forecasting FULL Model ═══
  Variables: 8
  Forecast origins: 227
  Using 20 parallel workers

  Starting parallel forecasting...
  Progress:
    Batch 1/5: Origins 1-50... Done.
      [Checkpoint saved: 50/227 origins]
    Batch 2/5: Origins 51-100... Done.
      [Checkpoint saved: 100/227 origins]
    Batch 3/5: Origins 101-150... Done.
      [Checkpoint saved: 150/227 origins]
    Batch 4/5: Origins 151-200... Done.
      [Checkpoint saved: 200/227 origins]
    Batch 5/5: Origins 201-227... Done.
      [Checkpoint saved: 227/227 origins]

  ✓ FULL model complete in 29.7 minutes
  Average time per origin: 7.8 seconds

Step 6: Cleaning up parallel cluster...
  ✓ Cluster stopped.

Step 7: Saving final results...
  ✓ Saved to results/forecasts/

═══════════════════════════════════════════════════
  RECURSIVE FORECASTING COMPLETE
═══════════════════════════════════════════════════

Summary:
  Total forecast origins: 227
  Forecast horizons: h = 1, 3, 12
  Successful runs (Small): 227/227
  Successful runs (Medium): 227/227
  Successful runs (Full): 227/227

Average hyperparameters:
  Small  - Lambda: 0.8652, Alpha: 3.0000
  Medium - Lambda: 0.7156, Alpha: 3.0000
  Full   - Lambda: 0.4661, Alpha: 3.0000

✓ Next step: Run 06_forecast_evaluation.R


✓ Phase 5 complete.

═══════════════════════════════════════════════════
  PHASE 6: FORECAST EVALUATION
═══════════════════════════════════════════════════

=== Forecast Evaluation ===

Step 1: Loading forecasts and evaluation data...
  Forecasts loaded: 227 origins per model

Step 2: Transforming BVAR forecasts to growth rates...
  Processing Small model...
  Processing Medium model...
  Processing Full model...
  ✓ Forecasts transformed to growth rates for all models.

Step 3: Aligning forecasts with realized values...
  ✓ Forecasts aligned with actuals for all models.

Step 4: Computing RMSFE for all models and horizons...

RMSFE Results (All Models):
   model variable       h1       h3      h12
1  Small      CPI 3.457042 2.636441 1.302849
2  Small   INDPRO 7.646022 5.544573 4.984304
3 Medium      CPI 2.987113 2.505337 1.354992
4 Medium   INDPRO 7.321818 4.968425 4.377778
5   Full      CPI 3.130966 2.537629 1.330283
6   Full   INDPRO 7.423961 5.082684 4.387710

Step 5: Computing Random Walk benchmarks...

Random Walk RMSFE (Benchmark):
  variable       h1       h3      h12
1      CPI 4.056634 3.267106 2.380577
2   INDPRO 8.012348 5.679765 4.293546

Step 5.5: Computing AR(1) benchmarks (evaluation growth rates)...

AR(1) RMSFE (Benchmark):
  variable       h1       h3      h12
1      CPI 3.226223 2.932742 1.534712
2   INDPRO 8.116537 4.787677 6.677762

Step 6: Computing relative RMSFE vs benchmarks...

Relative RMSFE (< 1 = Better than benchmark):

vs Random Walk:
   model variable rel_h1_rw rel_h3_rw rel_h12_rw
1  Small      CPI 0.8521947 0.8069651  0.5472829
2  Small   INDPRO 0.9542798 0.9761977  1.1608830
3 Medium      CPI 0.7363528 0.7668368  0.5691863
4 Medium   INDPRO 0.9138167 0.8747589  1.0196183
5   Full      CPI 0.7718138 0.7767207  0.5588070
6   Full   INDPRO 0.9265650 0.8948758  1.0219316

vs AR(1):
   model variable rel_h1_ar1 rel_h3_ar1 rel_h12_ar1
1  Small      CPI  1.0715446  0.8989679   0.8489211
2  Small   INDPRO  0.9420301  1.1580925   0.7464034
3 Medium      CPI  0.9258856  0.8542646   0.8828966
4 Medium   INDPRO  0.9020864  1.0377527   0.6555756
5   Full      CPI  0.9704741  0.8652753   0.8667968
6   Full   INDPRO  0.9146710  1.0616179   0.6570630

Relative RMSFE interpretation (lower is better):
  CPI h1 vs RW: best = Medium (0.736)
  CPI h3 vs RW: best = Medium (0.767)
  CPI h12 vs RW: best = Small (0.547)
  INDPRO h1 vs RW: best = Medium (0.914)
  INDPRO h3 vs RW: best = Medium (0.875)
  INDPRO h12 vs RW: best = Medium (1.020)

Step 7: Diebold-Mariano tests...

=== DM Test vs Benchmarks (H0: Equal accuracy) ===

DM test summary (first 12 rows):
 model variable horizon benchmark  statistic     p_value
 Small      CPI     h=1        RW -3.2222522 0.001459454
 Small      CPI     h=1       AR1  2.1637514 0.031532007
 Small      CPI     h=3        RW -1.6818460 0.093992249
 Small      CPI     h=3       AR1 -1.5995076 0.111117350
 Small      CPI    h=12        RW -1.6131535 0.108177959
 Small      CPI    h=12       AR1 -0.8210023 0.412554364
 Small   INDPRO     h=1        RW -1.0860633 0.278608027
 Small   INDPRO     h=1       AR1 -1.1412692 0.254965755
 Small   INDPRO     h=3        RW -0.1744003 0.861708375
 Small   INDPRO     h=3       AR1  1.5366628 0.125787198
 Small   INDPRO    h=12        RW  1.0651068 0.288022275
 Small   INDPRO    h=12       AR1 -0.3514755 0.725575880

DM tests vs benchmarks (significant at 5%):
  Small CPI h=1: better than RW (t=-3.22, p=0.001)
  Small CPI h=1: worse than AR1 (t=2.16, p=0.032)
  Medium CPI h=1: better than RW (t=-4.50, p=0.000)
  Medium CPI h=1: better than AR1 (t=-2.14, p=0.033)
  Medium CPI h=3: better than RW (t=-2.55, p=0.011)
  Medium CPI h=3: better than AR1 (t=-2.27, p=0.024)
  Full CPI h=1: better than RW (t=-4.57, p=0.000)
  Full CPI h=3: better than RW (t=-2.04, p=0.043)
  Full CPI h=3: better than AR1 (t=-2.39, p=0.018)


DM model comparison summary (first 12 rows):
 model_a model_b variable horizon  statistic     p_value
   Small  Medium      CPI     h=1  2.5411042 0.011720628
   Small  Medium      CPI     h=3  1.4641248 0.144561800
   Small  Medium      CPI    h=12 -0.7852949 0.433145196
   Small  Medium   INDPRO     h=1  2.4380334 0.015539508
   Small  Medium   INDPRO     h=3  1.8481660 0.065896516
   Small  Medium   INDPRO    h=12  1.6962031 0.091294810
   Small    Full      CPI     h=1  3.2617446 0.001278531
   Small    Full      CPI     h=3  1.4005577 0.162730070
   Small    Full      CPI    h=12 -0.3817688 0.703009934
   Small    Full   INDPRO     h=1  1.2548083 0.210844416
   Small    Full   INDPRO     h=3  1.0470598 0.296200489
   Small    Full   INDPRO    h=12  1.6274714 0.105101609

DM model comparisons (significant at 5%):
  Small vs Medium CPI h=1: worse than (t=2.54, p=0.012)
  Small vs Medium INDPRO h=1: worse than (t=2.44, p=0.016)
  Small vs Full CPI h=1: worse than (t=3.26, p=0.001)


Step 7.5: Clark-West (2007) tests for nested models...

Clark-West test summary:
 smaller_model larger_model variable horizon n_obs    estimate    se_hac
         Small       Medium      CPI     h=1   227  4.72126000 1.3841802
         Small       Medium      CPI     h=3   225  1.26470624 0.5398059
         Small       Medium      CPI    h=12   216 -0.02904288 0.1663669
         Small       Medium   INDPRO     h=1   227  7.28793059 2.2610245
         Small       Medium   INDPRO     h=3   225  8.26907300 3.6604723
         Small       Medium   INDPRO    h=12   216  7.47319902 3.4151302
        Medium         Full      CPI     h=1   227 -0.64935004 0.5479707
        Medium         Full      CPI     h=3   225 -0.07866204 0.2802957
        Medium         Full      CPI    h=12   216  0.09872628 0.1200992
        Medium         Full   INDPRO     h=1   227  0.25202992 1.5736672
        Medium         Full   INDPRO     h=3   225  0.16305489 2.0385931
        Medium         Full   INDPRO    h=12   216  0.30122210 1.0469159
      t_stat p_value_one_sided nw_lag
  3.41087103      0.0003834822      1
  2.34289074      0.0100057370      3
 -0.17457123      0.5692095832     12
  3.22328691      0.0007272128      1
  2.25901804      0.0124224023      3
  2.18826180      0.0148639118     12
 -1.18500860      0.8813706821      1
 -0.28063950      0.6103770290      3
  0.82203953      0.2059825461     12
  0.16015453      0.4364512010      1
  0.07998403      0.4681606851      3
  0.28772331      0.3869178484     12

Step 8: Saving evaluation results...
  ✓ Saved to results/tables/ and results/forecasts/

✓ Forecast evaluation complete!
Next step: Run 07_cg_regression.R


✓ Phase 6 complete.

═══════════════════════════════════════════════════
  PHASE 7: COIBION-GORODNICHENKO REGRESSION
═══════════════════════════════════════════════════

=== Coibion-Gorodnichenko Regression Analysis ===

Step 1: Loading forecast results...
  Data loaded.

Step 2: Computing forecast revisions...
  Revision = F_{t+h|t} - F_{t+h|t-1}

  Forecast revisions computed.

Step 3: Merging forecast errors with revisions...
Step 4: Estimating CG regressions...
  Regression: (Actual - Forecast) = alpha + beta * (Forecast_t - Forecast_{t-1}) + eps
  Using Newey-West HAC standard errors


=== CG Regression Results (Small Model) ===

 variable horizon       beta        se     t_stat    p_value n_obs
      CPI     h=1  2.5821600 1.2343129  2.0919818 0.03762500   215
      CPI     h=3  0.9299915 0.8482876  1.0963162 0.27417836   215
      CPI    h=12 -0.4927273 0.3496947 -1.4090214 0.16028704   215
   INDPRO     h=1  0.7138325 0.5761346  1.2390030 0.21670795   215
   INDPRO     h=3  0.9695622 0.5358617  1.8093517 0.07180617   215
   INDPRO    h=12  0.2365520 0.5233130  0.4520277 0.65170898   215

Step 5: Interpretation of beta coefficients:

h=1:
Model:  Small CPI 
  beta = 2.5822 (SE = 1.2343)
  95% CI: [0.1629, 5.0014]
  -> beta > 0: Under-reaction to news (sticky information)

Model:  Small INDPRO 
  beta = 0.7138 (SE = 0.5761)
  95% CI: [-0.4154, 1.8431]
  -> Not significantly different from 0 (rational expectations)

Model:  Medium CPI 
  beta = 0.7028 (SE = 0.2909)
  95% CI: [0.1326, 1.2730]
  -> beta > 0: Under-reaction to news (sticky information)

Model:  Medium INDPRO 
  beta = 0.2198 (SE = 0.4760)
  95% CI: [-0.7132, 1.1529]
  -> Not significantly different from 0 (rational expectations)

Model:  Full CPI 
  beta = 0.9051 (SE = 0.3092)
  95% CI: [0.2991, 1.5111]
  -> beta > 0: Under-reaction to news (sticky information)

Model:  Full INDPRO 
  beta = 0.0772 (SE = 0.3409)
  95% CI: [-0.5909, 0.7453]
  -> Not significantly different from 0 (rational expectations)

h=3:
Model:  Small CPI 
  beta = 0.9300 (SE = 0.8483)
  95% CI: [-0.7327, 2.5926]
  -> Not significantly different from 0 (rational expectations)

Model:  Small INDPRO 
  beta = 0.9696 (SE = 0.5359)
  95% CI: [-0.0807, 2.0199]
  -> Not significantly different from 0 (rational expectations)

Model:  Medium CPI 
  beta = 0.5494 (SE = 0.3213)
  95% CI: [-0.0804, 1.1792]
  -> Not significantly different from 0 (rational expectations)

Model:  Medium INDPRO 
  beta = 0.5940 (SE = 0.3544)
  95% CI: [-0.1006, 1.2886]
  -> Not significantly different from 0 (rational expectations)

Model:  Full CPI 
  beta = 0.6730 (SE = 0.3768)
  95% CI: [-0.0654, 1.4115]
  -> Not significantly different from 0 (rational expectations)

Model:  Full INDPRO 
  beta = 0.1713 (SE = 0.3461)
  95% CI: [-0.5070, 0.8496]
  -> Not significantly different from 0 (rational expectations)

h=12:
Model:  Small CPI 
  beta = -0.4927 (SE = 0.3497)
  95% CI: [-1.1781, 0.1927]
  -> Not significantly different from 0 (rational expectations)

Model:  Small INDPRO 
  beta = 0.2366 (SE = 0.5233)
  95% CI: [-0.7891, 1.2622]
  -> Not significantly different from 0 (rational expectations)

Model:  Medium CPI 
  beta = -0.1092 (SE = 0.2117)
  95% CI: [-0.5241, 0.3056]
  -> Not significantly different from 0 (rational expectations)

Model:  Medium INDPRO 
  beta = 0.3340 (SE = 0.5297)
  95% CI: [-0.7041, 1.3722]
  -> Not significantly different from 0 (rational expectations)

Model:  Full CPI 
  beta = -0.0661 (SE = 0.2244)
  95% CI: [-0.5059, 0.3736]
  -> Not significantly different from 0 (rational expectations)

Model:  Full INDPRO 
  beta = 0.1607 (SE = 0.4720)
  95% CI: [-0.7644, 1.0857]
  -> Not significantly different from 0 (rational expectations)

Step 6: Saving CG regression results...
  Saved to results/tables/ and results/forecasts.


=== Testing for Overreaction: DeltaBeta_h = beta_Full - beta_Small ===


DeltaBeta_h = beta_Full - beta_Small:
 variable horizon   beta_full beta_small  delta_beta  se_delta     t_stat
      CPI     h=1  0.90512574  2.5821600 -1.67703427 1.2724448 -1.3179623
      CPI     h=3  0.67300849  0.9299915 -0.25698301 0.9281927 -0.2768639
      CPI    h=12 -0.06614498 -0.4927273  0.42658228 0.4154795  1.0267228
   INDPRO     h=1  0.07719671  0.7138325 -0.63663580 0.6694212 -0.9510243
   INDPRO     h=3  0.17131906  0.9695622 -0.79824313 0.6378917 -1.2513772
   INDPRO    h=12  0.16065906  0.2365520 -0.07589295 0.7047089 -0.1076941
   p_value                  interpretation
 0.1889319 More overreaction in Full model
 0.7821531 More overreaction in Full model
 0.3057156 Less overreaction in Full model
 0.3426699 More overreaction in Full model
 0.2121695 More overreaction in Full model
 0.9143398 More overreaction in Full model

Interpretation:
  CPI h=1: DeltaBeta = -1.6770 (p = 0.189, not significant)
  CPI h=3: DeltaBeta = -0.2570 (p = 0.782, not significant)
  CPI h=12: DeltaBeta = 0.4266 (p = 0.306, not significant)
  INDPRO h=1: DeltaBeta = -0.6366 (p = 0.343, not significant)
  INDPRO h=3: DeltaBeta = -0.7982 (p = 0.212, not significant)
  INDPRO h=12: DeltaBeta = -0.0759 (p = 0.914, not significant)

Saved to results/tables/delta_beta_overreaction_test.csv


Next Steps:
  2. Run 08_visualization.R to create figures

✓ Phase 7 complete.

═══════════════════════════════════════════════════
  PHASE 8: VISUALIZATION
═══════════════════════════════════════════════════


=== Generating Visualization ===

Step 1: Loading analysis results...
  ?Data loaded.

Step 2: Creating RMSFE comparison plot...
  ?Saved: fig1_rmsfe_comparison.png

Step 3: Creating relative RMSFE plot...
  ?Saved: fig2_relative_rmsfe.png

Step 4: Creating CG regression coefficient plot...
  ?Saved: fig3_cg_coefficients.png

Step 5: Creating _h plot...
  ?Saved: fig4_delta_beta_overreaction.png

Step 6: Creating hyperparameter evolution plot...
  ?Saved: fig5_lambda_evolution.png

Step 7: Creating forecast vs actual plots...
  Fig6 uses variable=CPI, model=Small (cpi_small)
  Fig6 alignment spot-check (first 5 rows):
    h=1:
 origin_date target_date
  2001-01-31  2001-02-28
  2001-02-28  2001-03-31
  2001-03-31  2001-04-30
  2001-04-30  2001-05-31
  2001-05-31  2001-06-30
    h=3:
 origin_date target_date
  2001-01-31  2001-04-30
  2001-02-28  2001-05-31
  2001-03-31  2001-06-30
  2001-04-30  2001-07-31
  2001-05-31  2001-08-31
    h=12:
 origin_date target_date
  2001-01-31  2002-01-31
  2001-02-28  2002-02-28
  2001-03-31  2002-03-31
  2001-04-30  2002-04-30
  2001-05-31  2002-05-31

  ?Saved: fig6a_forecast_vs_actual_h1.png
  ?Saved: fig6b_forecast_vs_actual_h3.png
  ?Saved: fig6c_forecast_vs_actual_h12.png

  ?Saved: fig6d_timing_diagnostic_h1.png
  ?Saved: fig6e_timing_diagnostic_h3.png
  ?Saved: fig6f_timing_diagnostic_h12.png

Step 8: Creating CG regression scatter plots...
  ?Saved: fig7a_cg_scatter_h1.png
  ?Saved: fig7b_cg_scatter_h3.png
  ?Saved: fig7c_cg_scatter_h12.png


  VISUALIZATION COMPLETE


Generated figures:
  1. fig1_rmsfe_comparison.png - Forecast accuracy comparison
  2. fig2_relative_rmsfe.png - Performance vs. RW benchmark
  3. fig3_cg_coefficients.png - CG regression coefficients (all models)
  4. fig4_delta_beta_overreaction.png - Overreaction test (_h)
  5. fig5_lambda_evolution.png - Hyperparameter dynamics
  6a-c. Forecast vs Actual (h=1, 3, 12):
     - fig6a_forecast_vs_actual_h1.png
     - fig6b_forecast_vs_actual_h3.png
     - fig6c_forecast_vs_actual_h12.png
  6d-f. Timing diagnostic:
     - fig6d_timing_diagnostic_h1.png
     - fig6e_timing_diagnostic_h3.png
     - fig6f_timing_diagnostic_h12.png
  7a-c. CG Regression Scatter Plots (h=1, 3, 12):
     - fig7a_cg_scatter_h1.png
     - fig7b_cg_scatter_h3.png
     - fig7c_cg_scatter_h12.png

Total: 14 publication-quality figures
All figures saved to: results/figures/


✓ Phase 8 complete.

=============================================================================
  PHASE 9-11: ROBUSTNESS SUITE (AUTO-EXECUTE)
=============================================================================

Auto-running robustness checks...

=== Robustness Checks ===

Step 1: Loading estimation data...
  Data loaded.


========================================
Scenario: lag6
========================================

  Forecast origins: 227

Forecasting SMALL model (lags=6)...
  Done in 5.2 minutes (0 failures)

Forecasting MEDIUM model (lags=6)...
  Done in 8.4 minutes (0 failures)

Forecasting FULL model (lags=6)...
  Done in 19.1 minutes (0 failures)

Relative RMSFE interpretation (vs RW):
  CPI rel_h1: best = Medium (0.736)
  CPI rel_h3: best = Medium (0.760)
  CPI rel_h12: best = Small (0.543)
  INDPRO rel_h1: best = Medium (0.911)
  INDPRO rel_h3: best = Medium (0.864)
  INDPRO rel_h12: best = Medium (1.005)

  Results saved to:  results/robustness/lag6 

========================================
Scenario: window1995
========================================

  Forecast origins: 287

Forecasting SMALL model (lags=12)...
  Done in 19.7 minutes (0 failures)

Forecasting MEDIUM model (lags=12)...
  Done in 40.3 minutes (0 failures)

Forecasting FULL model (lags=12)...
  Done in 39.8 minutes (0 failures)

Relative RMSFE interpretation (vs RW):
  CPI rel_h1: best = Medium (0.735)
  CPI rel_h3: best = Medium (0.736)
  CPI rel_h12: best = Small (0.549)
  INDPRO rel_h1: best = Medium (0.888)
  INDPRO rel_h3: best = Medium (0.822)
  INDPRO rel_h12: best = Medium (0.946)

  Results saved to:  results/robustness/window1995 

Robustness checks complete.


✓ Phase 9 complete.

=== Robustness Visualization ===

  Saved: results/figures/fig_robustness_relative_rmsfe_rw.png
  Saved: results/figures/fig_robustness_relative_rmsfe_ar1.png

Robustness visualization complete.


✓ Phase 10 complete.

=== Robustness Extension: Error Decomposition & Rolling RMSFE ===

Step 1: Loading aligned forecasts/actuals...
  Runs detected: 3 (baseline + robustness scenarios)

Step 2: Validating 'forecast vs actual' time alignment...
  (Checks that stored actual at origin t matches realized growth ending at t+h)

  [baseline]
# A tibble: 6 × 3
  variable horizon max_abs_diff
  <chr>      <dbl>        <dbl>
1 CPI            1            0
2 INDPRO         1            0
3 CPI            3            0
4 INDPRO         3            0
5 CPI           12            0
6 INDPRO        12            0

  [lag6]
# A tibble: 6 × 3
  variable horizon max_abs_diff
  <chr>      <dbl>        <dbl>
1 CPI            1            0
2 INDPRO         1            0
3 CPI            3            0
4 INDPRO         3            0
5 CPI           12            0
6 INDPRO        12            0

  [window1995]
# A tibble: 6 × 3
  variable horizon max_abs_diff
  <chr>      <dbl>        <dbl>
1 CPI            1            0
2 INDPRO         1            0
3 CPI            3            0
4 INDPRO         3            0
5 CPI           12            0
6 INDPRO        12            0

Step 3: Computing Theil error decomposition...
  [baseline] Saved: results/tables/error_decomposition.csv
  Saved: results/figures/fig_error_decomposition.png

  [baseline] Decomposition highlights (lowest RMSE among BVAR models):
    CPI h=1: best=Medium (RMSE=2.987; bias=-0.055, over-predicts; bias share=0.00)
    CPI h=3: best=Medium (RMSE=2.505; bias=-0.088, over-predicts; bias share=0.00)
    CPI h=12: best=Small (RMSE=1.303; bias=-0.150, over-predicts; bias share=0.01)
    INDPRO h=1: best=Medium (RMSE=7.322; bias=-1.205, over-predicts; bias share=0.03)
    INDPRO h=3: best=Medium (RMSE=4.968; bias=-1.249, over-predicts; bias share=0.06)
    INDPRO h=12: best=Medium (RMSE=4.378; bias=-1.297, over-predicts; bias share=0.09)

  [lag6] Saved: results/robustness/lag6/tables/error_decomposition.csv
  Saved: results/robustness/lag6/figures/fig_error_decomposition.png

  [lag6] Decomposition highlights (lowest RMSE among BVAR models):
    CPI h=1: best=Medium (RMSE=2.985; bias=-0.116, over-predicts; bias share=0.00)
    CPI h=3: best=Medium (RMSE=2.483; bias=-0.135, over-predicts; bias share=0.00)
    CPI h=12: best=Small (RMSE=1.293; bias=-0.209, over-predicts; bias share=0.03)
    INDPRO h=1: best=Medium (RMSE=7.301; bias=-1.337, over-predicts; bias share=0.03)
    INDPRO h=3: best=Medium (RMSE=4.907; bias=-1.361, over-predicts; bias share=0.08)
    INDPRO h=12: best=Medium (RMSE=4.313; bias=-1.340, over-predicts; bias share=0.10)

  [window1995] Saved: results/robustness/window1995/tables/error_decomposition.csv
  Saved: results/robustness/window1995/figures/fig_error_decomposition.png

  [window1995] Decomposition highlights (lowest RMSE among BVAR models):
    CPI h=1: best=Medium (RMSE=2.855; bias=-0.170, over-predicts; bias share=0.00)
    CPI h=3: best=Medium (RMSE=2.328; bias=-0.206, over-predicts; bias share=0.01)
    CPI h=12: best=Small (RMSE=1.324; bias=-0.291, over-predicts; bias share=0.05)
    INDPRO h=1: best=Medium (RMSE=7.050; bias=-0.851, over-predicts; bias share=0.01)
    INDPRO h=3: best=Medium (RMSE=4.691; bias=-0.942, over-predicts; bias share=0.04)
    INDPRO h=12: best=Medium (RMSE=4.240; bias=-1.158, over-predicts; bias share=0.07)

Step 4: Computing rolling RMSFE and rolling relative RMSFE...
  Rolling window: 60 months

  [baseline] Saved: results/tables/rolling_rmsfe.csv
  [baseline] Saved: results/tables/rolling_relative_rmsfe_vs_rw.csv
  [baseline] Saved: results/tables/rolling_relative_rmsfe_vs_ar1.csv
  Saved: results/figures/fig_rolling_relative_rmsfe_rw.png
  Saved: results/figures/fig_rolling_relative_rmsfe_ar1.png

  [baseline] Rolling relative RMSFE averages (vs RW):
# A tibble: 18 × 4
   model  variable horizon avg_rel
   <chr>  <chr>      <dbl>   <dbl>
 1 Medium CPI            1   0.736
 2 Full   CPI            1   0.768
 3 Small  CPI            1   0.863
 4 Medium CPI            3   0.771
 5 Full   CPI            3   0.780
 6 Small  CPI            3   0.816
 7 Small  CPI           12   0.608
 8 Full   CPI           12   0.613
 9 Medium CPI           12   0.615
10 Medium INDPRO         1   0.932
11 Small  INDPRO         1   0.962
12 Full   INDPRO         1   0.962
13 Medium INDPRO         3   0.885
14 Full   INDPRO         3   0.951
15 Small  INDPRO         3   0.969
16 Medium INDPRO        12   0.956
17 Full   INDPRO        12   0.986
18 Small  INDPRO        12   1.11 

  [lag6] Saved: results/robustness/lag6/tables/rolling_rmsfe.csv
  [lag6] Saved: results/robustness/lag6/tables/rolling_relative_rmsfe_vs_rw.csv
  [lag6] Saved: results/robustness/lag6/tables/rolling_relative_rmsfe_vs_ar1.csv
  Saved: results/robustness/lag6/figures/fig_rolling_relative_rmsfe_rw.png
  Saved: results/robustness/lag6/figures/fig_rolling_relative_rmsfe_ar1.png

  [lag6] Rolling relative RMSFE averages (vs RW):
# A tibble: 18 × 4
   model  variable horizon avg_rel
   <chr>  <chr>      <dbl>   <dbl>
 1 Medium CPI            1   0.738
 2 Full   CPI            1   0.780
 3 Small  CPI            1   0.864
 4 Medium CPI            3   0.770
 5 Full   CPI            3   0.782
 6 Small  CPI            3   0.824
 7 Full   CPI           12   0.596
 8 Medium CPI           12   0.600
 9 Small  CPI           12   0.613
10 Medium INDPRO         1   0.934
11 Full   INDPRO         1   0.958
12 Small  INDPRO         1   0.960
13 Medium INDPRO         3   0.886
14 Full   INDPRO         3   0.942
15 Small  INDPRO         3   0.961
16 Medium INDPRO        12   0.942
17 Full   INDPRO        12   0.977
18 Small  INDPRO        12   1.07 

  [window1995] Saved: results/robustness/window1995/tables/rolling_rmsfe.csv
  [window1995] Saved: results/robustness/window1995/tables/rolling_relative_rmsfe_vs_rw.csv
  [window1995] Saved: results/robustness/window1995/tables/rolling_relative_rmsfe_vs_ar1.csv
  Saved: results/robustness/window1995/figures/fig_rolling_relative_rmsfe_rw.png
  Saved: results/robustness/window1995/figures/fig_rolling_relative_rmsfe_ar1.png

  [window1995] Rolling relative RMSFE averages (vs RW):
# A tibble: 18 × 4
   model  variable horizon avg_rel
   <chr>  <chr>      <dbl>   <dbl>
 1 Medium CPI            1   0.726
 2 Full   CPI            1   0.774
 3 Small  CPI            1   0.828
 4 Medium CPI            3   0.713
 5 Full   CPI            3   0.723
 6 Small  CPI            3   0.747
 7 Full   CPI           12   0.554
 8 Small  CPI           12   0.557
 9 Medium CPI           12   0.565
10 Medium INDPRO         1   0.926
11 Full   INDPRO         1   0.943
12 Small  INDPRO         1   0.958
13 Medium INDPRO         3   0.891
14 Full   INDPRO         3   0.938
15 Small  INDPRO         3   0.971
16 Medium INDPRO        12   1.00 
17 Full   INDPRO        12   1.04 
18 Small  INDPRO        12   1.12 

✓ Robustness extension complete.
Outputs:
  - Baseline tables: results/tables/error_decomposition.csv, results/tables/rolling_relative_rmsfe_vs_*.csv
  - Baseline figures: results/figures/fig_error_decomposition.png, results/figures/fig_rolling_relative_rmsfe_*.png
  - Robustness scenarios (if present): results/robustness/<scenario>/{tables,figures}/


✓ Phase 11 complete.

═══════════════════════════════════════════════════
  PHASE 12: OIL PRICE ROBUSTNESS CHECK
═══════════════════════════════════════════════════

Testing sentiment predictive power after controlling for oil prices...

=== Oil Price Robustness Check ===

Research Question: Does sentiment contain information beyond oil prices?
Note: This analysis uses already-generated forecasts from the main models.

Step 1: Loading forecast results and data...
  Data loaded.

Step 2: Analyzing oil price control...

Key comparisons:
  1. Small (no oil, no sentiment) vs Medium (with oil, no sentiment)
     → Tests marginal value of oil prices

  2. Medium (with oil, no sentiment) vs Full (with oil+sentiment)
     → Tests marginal value of sentiment AFTER controlling for oil

Step 3: Comparing forecast accuracy across models...

Step 4: Computing incremental improvements...

Step 5: Saving results...
  Saved to results/robustness/oil_control/tables/


=== Oil Price Robustness Results ===

RMSFE Comparison:
                 model variable       h1       h3      h12
      Small (baseline)      CPI 3.457042 2.636441 1.302849
         Medium (+oil)      CPI 2.987113 2.505337 1.354992
 Full (+oil+sentiment)      CPI 3.130966 2.537629 1.330283
      Small (baseline)   INDPRO 7.646022 5.544573 4.984304
         Medium (+oil)   INDPRO 7.321818 4.968425 4.377778
 Full (+oil+sentiment)   INDPRO 7.423961 5.082684 4.387710

Incremental Improvements (%):
 variable                 comparison h1_improvement_pct h3_improvement_pct
      CPI      Oil (Medium vs Small)          13.593371           4.972739
      CPI Sentiment (Full vs Medium)          -4.815773          -1.288913
   INDPRO      Oil (Medium vs Small)           4.240174          10.391210
   INDPRO Sentiment (Full vs Medium)          -1.395059          -2.299701
 h12_improvement_pct
          -4.0021981
           1.8235197
          12.1687267
          -0.2268791

Interpretation:
  CPI h=12:
    - Oil adds: -4.00% improvement over Small model
    - Sentiment adds: 1.82% improvement AFTER controlling for oil

  ✓ CONCLUSION: Sentiment retains predictive power after controlling for oil prices.

  INDPRO h=12:
    - Oil adds: 12.17% improvement over Small model
    - Sentiment adds: -0.23% improvement AFTER controlling for oil

✓ Oil price robustness check complete!


✓ Phase 12 complete.

═══════════════════════════════════════════════════
  PHASE 13: BAYESIAN CG CREDIBLE INTERVALS
═══════════════════════════════════════════════════

Computing Bayesian credible intervals for CG coefficients...

=== Bootstrap Inference for CG Regression Coefficients ===

Purpose: Quantify uncertainty in CG regression β coefficients
Method: Block bootstrap on forecast origins

Step 1: Loading CG regression results from CSV files...
  Loaded CG regression results table.
  Found 18 model-variable-horizon combinations

  Loaded detailed CG data for bootstrap.

Step 2: Computing confidence intervals...

95% Confidence Intervals (Asymptotic):
 variable horizon        beta        se    ci_lower  ci_upper    p_value
      CPI     h=1  2.58216001 1.2343129  0.16290680 5.0014132 0.03762500
      CPI     h=3  0.92999151 0.8482876 -0.73265224 2.5926353 0.27417836
      CPI    h=12 -0.49272726 0.3496947 -1.17812881 0.1926743 0.16028704
   INDPRO     h=1  0.71383252 0.5761346 -0.41539131 1.8430563 0.21670795
   INDPRO     h=3  0.96956218 0.5358617 -0.08072666 2.0198510 0.07180617
   INDPRO    h=12  0.23655201 0.5233130 -0.78914156 1.2622456 0.65170898
      CPI     h=1  0.70281036 0.2909319  0.13258380 1.2730369 0.01654763
      CPI     h=3  0.54936302 0.3213287 -0.08044127 1.1791673 0.08878498
      CPI    h=12 -0.10923929 0.2116556 -0.52408424 0.3056057 0.60630726
   INDPRO     h=1  0.21982391 0.4760390 -0.71321251 1.1528603 0.64471244
   INDPRO     h=3  0.59397469 0.3543869 -0.10062365 1.2885730 0.09519308
   INDPRO    h=12  0.33401974 0.5296662 -0.70412599 1.3721655 0.52896301
      CPI     h=1  0.90512574 0.3091725  0.29914773 1.5111038 0.00378722
      CPI     h=3  0.67300849 0.3767622 -0.06544543 1.4114624 0.07547385
      CPI    h=12 -0.06614498 0.2243588 -0.50588817 0.3735982 0.76842014
   INDPRO     h=1  0.07719671 0.3408719 -0.59091212 0.7453055 0.82105430
   INDPRO     h=3  0.17131906 0.3460608 -0.50696012 0.8495982 0.62107174
   INDPRO    h=12  0.16065906 0.4719725 -0.76440705 1.0857252 0.73389140
 significant n_obs
        TRUE   215
       FALSE   215
       FALSE   215
       FALSE   215
       FALSE   215
       FALSE   215
        TRUE   215
       FALSE   215
       FALSE   215
       FALSE   215
       FALSE   215
       FALSE   215
        TRUE   215
       FALSE   215
       FALSE   215
       FALSE   215
       FALSE   215
       FALSE   215

Step 3: Computing Δβ (Full - Small) confidence intervals...

Δβ Confidence Intervals:
 variable horizon  delta_beta  se_delta   ci_lower  ci_upper   p_value
      CPI     h=1 -1.67703427 1.2724448 -4.1710261 0.8169576 0.1889319
      CPI     h=3 -0.25698301 0.9281927 -2.0762407 1.5622746 0.7821531
      CPI    h=12  0.42658228 0.4154795 -0.3877575 1.2409221 0.3057156
   INDPRO     h=1 -0.63663580 0.6694212 -1.9487013 0.6754297 0.3426699
   INDPRO     h=3 -0.79824313 0.6378917 -2.0485108 0.4520246 0.2121695
   INDPRO    h=12 -0.07589295 0.7047089 -1.4571223 1.3053364 0.9143398
 significant
       FALSE
       FALSE
       FALSE
       FALSE
       FALSE
       FALSE

Step 4: Running bootstrap for refined intervals (Small CPI only)...
  This provides finite-sample-corrected intervals...

Step 5: Saving results...
  Saved to results/bayesian_cg/


=== CG Regression Uncertainty Quantification ===

Key Results:

Significant Underreaction Found:
  CPI h=1: β = 2.582, 95% CI [0.163, 5.001] (p = 0.038)
  CPI h=1: β = 0.905, 95% CI [0.299, 1.511] (p = 0.004)
  CPI h=1: β = 0.703, 95% CI [0.133, 1.273] (p = 0.017)

Sentiment's Effect on Forecast Bias:
  CPI h=1: Δβ = -1.677, 95% CI [-4.171, 0.817] → Not significant
  CPI h=3: Δβ = -0.257, 95% CI [-2.076, 1.562] → Not significant
  CPI h=12: Δβ = 0.427, 95% CI [-0.388, 1.241] → Not significant
  INDPRO h=1: Δβ = -0.637, 95% CI [-1.949, 0.675] → Not significant
  INDPRO h=3: Δβ = -0.798, 95% CI [-2.049, 0.452] → Not significant
  INDPRO h=12: Δβ = -0.076, 95% CI [-1.457, 1.305] → Not significant

✓ CG inference complete!

Note: Confidence intervals are based on Newey-West HAC standard errors,
      which are robust to heteroskedasticity and autocorrelation.
      Bootstrap intervals (if computed) provide finite-sample refinement.


✓ Phase 13 complete.

╔════════════════════════════════════════════════════════════════════╗
║                                                                    ║
║                  ANALYSIS PIPELINE COMPLETE                        ║
║                                                                    ║
╚════════════════════════════════════════════════════════════════════╝

Execution Summary:
  Start time: 2026-01-24 12:40:58
  End time: 2026-01-24 15:57:30
  Total elapsed time: 196.5 minutes

Output Files:
  Data:
    - data/processed/*.rds (estimation and evaluation data)
  Forecasts:
    - results/forecasts/*_model_forecasts.rds
    - results/forecasts/hyperparameters_evolution.csv
  Tables:
    - results/tables/rmsfe_results.csv
    - results/tables/relative_rmsfe.csv
    - results/tables/cg_regression_results.csv
  Diagnostics:
    - results/diagnostics/*.rds

Next Steps:
  1. Review results in results/tables/
  2. Integrate findings into ForecastingHorseRace.tex

Log saved to: results/analysis_log_20260124_124058.txt 

