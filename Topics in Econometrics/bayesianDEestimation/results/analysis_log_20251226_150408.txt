Analysis started at: 2025-12-26 15:04:08 


═══════════════════════════════════════════════════
  PHASE 1: ENVIRONMENT SETUP
═══════════════════════════════════════════════════

=== Initializing R-Julia Hybrid Environment ===

✓ CRAN mirror set to https://cloud.r-project.org
Step 1: Loading R packages...
✓ All R packages loaded successfully.

Step 2: Initializing Julia via JuliaCall...
✓ Julia initialized successfully.
  Julia version: 1.12.2
  Julia threads: 12

Step 3: Setting up Julia packages...
  Checking DataFrames.jl...
  Checking CSV.jl...
  Checking Statistics.jl...
✓ Julia packages loaded successfully.

Step 4: Loading Julia transformation functions...
✓ Loaded julia/transformation_functions.jl

Step 5: Configuring R parallel computing...
  Total cores: 20
  Cores for parallel: 14

Step 6: Verifying directory structure...
✓ Directory structure verified.

=== Environment Setup Complete ===

Configuration Summary:
  R version: R version 4.5.2 (2025-10-31 ucrt)
  Julia version: 1.12.2
  R parallel cores: 14
  Julia threads: 12
  Working directory: E:/IHEID Economics/IHEID/Topics in Econometrics/bayesianDEestimation

✓ Ready to proceed with data acquisition and analysis.

Session info saved to results/session_info.txt


✓ Phase 1 complete.

═══════════════════════════════════════════════════
  PHASE 2: DATA ACQUISITION
═══════════════════════════════════════════════════

⚠ Raw data already exists. Skip download? (y/n): 

=== Starting Data Acquisition ===

Step 1: Setting up FRED API connection...
✓ FRED API configured.

Step 2: Defining variable lists...
  Small model: 4 variables
  Medium model: 6 variables
  Full model: 7 variables

Step 3: Downloading data from FRED (1985-01-01 to 2019-12-31)...
  ✓ Downloaded INDPRO (420 observations)
  ✓ Downloaded CPIAUCSL (420 observations)
  ✓ Downloaded UNRATE (420 observations)
  ✓ Downloaded FEDFUNDS (420 observations)
  ✓ Downloaded GS10 (420 observations)
  Downloading ^GSPC from Yahoo Finance...
  ✓ Downloaded ^GSPC (420 observations)
  ✓ Downloaded UMCSENT (420 observations)

Step 4: Merging and cleaning data...

Missing values summary:
  INDPRO CPIAUCSL   UNRATE FEDFUNDS     GS10    SP500  UMCSENT 
       0        0        0        0        0        0        0 

✓ Clean dataset: 420 observations × 7 variables

Step 5: Creating three nested datasets...
  Small model: 4 vars
  Medium model: 6 vars
  Full model: 7 vars

Step 6: Saving raw data...
  ✓ Saved to data/raw/

=== Data Acquisition Summary ===

Sample period: 1985M1 - 2019M12
Total observations: 420
Variables downloaded: 7

Variable list:
# A tibble: 7 × 3
  var_name fred_code description                   
  <chr>    <chr>     <chr>                         
1 INDPRO   INDPRO    Industrial Production Index   
2 CPIAUCSL CPIAUCSL  Consumer Price Index          
3 UNRATE   UNRATE    Unemployment Rate             
4 FEDFUNDS FEDFUNDS  Federal Funds Rate            
5 GS10     GS10      10-Year Treasury Yield        
6 SP500    ^GSPC     S&P 500 Index                 
7 UMCSENT  UMCSENT   U. Michigan Consumer Sentiment

✓ Data acquisition complete!
Next step: Run 03_data_transformation.R


═══════════════════════════════════════════════════
  PHASE 3: DATA TRANSFORMATION
═══════════════════════════════════════════════════

=== Starting Data Transformation ===

Step 1: Loading raw data...
  Small: 420 obs × 4 vars
  Medium: 420 obs × 6 vars
  Full: 420 obs × 7 vars

Step 2: Applying transformations for BVAR estimation...
  (Log-levels for prices/quantities, levels for rates/indices)

  INDPRO: log transformation
  CPIAUCSL: log transformation
  UNRATE: level (no transformation)
  FEDFUNDS: level (no transformation)
  INDPRO: log transformation
  CPIAUCSL: log transformation
  UNRATE: level (no transformation)
  FEDFUNDS: level (no transformation)
  GS10: level (no transformation)
  SP500: log transformation
  INDPRO: log transformation
  CPIAUCSL: log transformation
  UNRATE: level (no transformation)
  FEDFUNDS: level (no transformation)
  GS10: level (no transformation)
  SP500: log transformation
  UMCSENT: level (no transformation)

Step 3: Creating estimation-ready matrices...
  ✓ Small estimation matrix: 420 × 4
  ✓ Medium estimation matrix: 420 × 6
  ✓ Full estimation matrix: 420 × 7

Step 4: Computing evaluation transforms using Julia...
  (Annualized growth rates for forecast evaluation)

  ✓ Evaluation transforms computed.
    Generated 12 series from small model
    Generated 18 series from medium model
    Generated 21 series from full model

Step 5: Saving processed data...
  ✓ Saved to data/processed/

=== Data Transformation Summary ===

Estimation-ready data (for BVAR input):
  - Log-levels: INDPRO, CPIAUCSL, SP500
  - Levels: UNRATE, FEDFUNDS, GS10, UMCSENT

Evaluation transforms (for forecast accuracy):
  - *_mom: Annualized month-over-month growth (1200 × Δlog)
  - *_yoy: Year-over-year growth (100 × Δ12log)
  - *_diff: Level change (Δ1)
  - *_diff12: 12-month level change (Δ12)

✓ Data transformation complete!
Next step: Run 04_bvar_estimation.R


✓ Phase 3 complete.

═══════════════════════════════════════════════════
  PHASE 4: BVAR ESTIMATION SETUP
═══════════════════════════════════════════════════

=== Hierarchical BVAR Estimation Setup ===

Step 1: Configuring hierarchical priors...

  ✓ Hierarchical priors configured:
    - Minnesota prior with automatic lambda selection
    - Sum-of-coefficients prior (unit-root accommodation)
    - Dummy-initial-observation prior

Step 2: Configuring MCMC parameters...
  Total draws: 10000
  Burn-in: 5000
  Effective draws: 5000

Step 3: Defining BVAR estimation function...

Step 4: Testing BVAR estimation on full sample...
  (This verifies the setup before recursive forecasting)

Data loaded. Estimating small model on full sample...
✓ Estimation successful!
Step 5: Optimal hyperparameters from test estimation:

Minnesota Prior:
  Hyperparameters auto-optimized via marginal likelihood
Minnesota Prior (Posterior Means):
  Lambda (tightness): 0.6536

Other Priors (Posterior Means):
  SOC (sum-of-coef): 0.4417
  SUR (dummy-init-obs): 0.6850

  Log-marginal likelihood (final): 3595.83
✓ Test estimation complete!
  BVAR setup verified and ready for recursive forecasting.

Step 6: Generating test forecasts (h=1,3,12)...
✓ Forecast generated.
  Forecast dimensions: 5000 horizons × 12 variables

Example: CPI forecasts (log-level):
  h=1:  4.6222
  h=3:  4.6209
  h=12: 4.6173

Step 7: Saving test estimation results...
  ✓ Saved to results/diagnostics/

=== BVAR Estimation Setup Complete ===

Key points:
  ✓ Hierarchical priors configured with automatic hyperparameter selection
  ✓ MCMC settings: 10000 draws with 5000 burn-in
  ✓ Test estimation successful on full sample
  ✓ Optimal lambda: 0.6536

✓ Phase 4 complete.

═══════════════════════════════════════════════════
  PHASE 5: RECURSIVE FORECASTING
═══════════════════════════════════════════════════

⚠ WARNING: This phase will take 30-45 minutes.
  Progress will be checkpointed every 50 origins.


=== Starting Recursive Forecasting (Parallelized) ===

  Progress will be saved with checkpoints every 50 origins.

Step 1: Loading data and configuration...
  ✓ Data and priors loaded.

Step 2: Defining forecast origins...
  Initial training window: 1985M1 - 2000-12-31 (192 obs)
  Final forecast origin: 2019-11-30
  Number of forecast origins: 227
  Forecast period: 2001-01 to 2019-11


Step 3: Setting up parallel forecasting function...
  ✓ Forecasting function defined.

Step 3.5: Running pre-flight test on first origin...
  ✓ Pre-flight test passed. Proceeding with parallel execution...

Step 4: Initializing parallel cluster...
  Cluster created with 14 workers.
  Exporting data and functions to workers...
  ✓ Cluster initialized.

╔════════════════════════════════════════════════════╗
║  RECURSIVE FORECASTING: ALL MODELS                 ║
╚════════════════════════════════════════════════════╝

═══ Forecasting SMALL Model ═══
  Variables: 4
  Forecast origins: 227
  Using 14 parallel workers

  Starting parallel forecasting...
  Progress:
    Batch 1/5: Origins 1-50... Done.
      [Checkpoint saved: 50/227 origins]
    Batch 2/5: Origins 51-100... Done.
      [Checkpoint saved: 100/227 origins]
    Batch 3/5: Origins 101-150... Done.
      [Checkpoint saved: 150/227 origins]
    Batch 4/5: Origins 151-200... Done.
      [Checkpoint saved: 200/227 origins]
    Batch 5/5: Origins 201-227... Done.
      [Checkpoint saved: 227/227 origins]

  ✓ SMALL model complete in 9.9 minutes
  Average time per origin: 2.6 seconds

═══ Forecasting MEDIUM Model ═══
  Variables: 6
  Forecast origins: 227
  Using 14 parallel workers

  Starting parallel forecasting...
  Progress:
    Batch 1/5: Origins 1-50... Done.
      [Checkpoint saved: 50/227 origins]
    Batch 2/5: Origins 51-100... Done.
      [Checkpoint saved: 100/227 origins]
    Batch 3/5: Origins 101-150... Done.
      [Checkpoint saved: 150/227 origins]
    Batch 4/5: Origins 151-200... Done.
      [Checkpoint saved: 200/227 origins]
    Batch 5/5: Origins 201-227... Done.
      [Checkpoint saved: 227/227 origins]

  ✓ MEDIUM model complete in 17.5 minutes
  Average time per origin: 4.6 seconds

═══ Forecasting FULL Model ═══
  Variables: 7
  Forecast origins: 227
  Using 14 parallel workers

  Starting parallel forecasting...
  Progress:
    Batch 1/5: Origins 1-50... Done.
      [Checkpoint saved: 50/227 origins]
    Batch 2/5: Origins 51-100... Done.
      [Checkpoint saved: 100/227 origins]
    Batch 3/5: Origins 101-150... Done.
      [Checkpoint saved: 150/227 origins]
    Batch 4/5: Origins 151-200... Done.
      [Checkpoint saved: 200/227 origins]
    Batch 5/5: Origins 201-227... Done.
      [Checkpoint saved: 227/227 origins]

  ✓ FULL model complete in 31.3 minutes
  Average time per origin: 8.3 seconds
  ⚠ Warning: 17/227 origins failed

  Sample error messages (first 3):
    Origin 403: Error in solve.default(XX + omega_inv, crossprod(X, Y) + omega_inv %*% : system 
    Origin 404: Error in solve.default(XX + omega_inv, crossprod(X, Y) + omega_inv %*% : system 
    Origin 405: Error in solve.default(XX + omega_inv, crossprod(X, Y) + omega_inv %*% : system 


Step 6: Cleaning up parallel cluster...
  ✓ Cluster stopped.

Step 7: Saving final results...
  ✓ Saved to results/forecasts/

═══════════════════════════════════════════════════
  RECURSIVE FORECASTING COMPLETE
═══════════════════════════════════════════════════

Summary:
  Total forecast origins: 227
  Forecast horizons: h = 1, 3, 12
  Successful runs (Small): 227/227
  Successful runs (Medium): 227/227
  Successful runs (Full): 210/227

Average hyperparameters:
  Small  - Lambda: 0.5210, Alpha: NaN
  Medium - Lambda: 0.4148, Alpha: NaN
  Full   - Lambda: 0.1823, Alpha: NaN

✓ Next step: Run 06_forecast_evaluation.R


✓ Phase 5 complete.

═══════════════════════════════════════════════════
  PHASE 6: FORECAST EVALUATION
═══════════════════════════════════════════════════

=== Forecast Evaluation ===

Step 1: Loading forecasts and evaluation data...
  Forecasts loaded: 227 origins per model

Step 2: Transforming BVAR forecasts to growth rates...
  ✓ Forecasts transformed to growth rates.

Step 3: Aligning forecasts with realized values...
  ✓ Forecasts aligned with actuals.

Step 4: Computing RMSFE for all models and horizons...

RMSFE Results (Small Model):
  model variable         h1        h3       h12
1 Small      CPI   4.711697   3.71599  3.918834
2 Small   INDPRO 973.271384 323.65114 80.112803

Step 5: Computing Random Walk benchmarks...

Random Walk RMSFE:
  variable       h1       h3      h12
1      CPI 4.056634 4.070302 4.105178
2   INDPRO 8.012348 8.029204 8.122549

Step 6: Computing relative RMSFE (vs Random Walk)...

Relative RMSFE (< 1 = Better than RW):
  model variable     rel_h1    rel_h3   rel_h12
1 Small      CPI   1.161479  0.912952 0.9546074
2 Small   INDPRO 121.471425 40.309245 9.8630125

Step 7: Diebold-Mariano test (BVAR vs RW)...

DM Test Results (H0: Equal predictive accuracy):
  CPI h=1: t = 1.80, p = 0.0733
  INDPRO h=1: t = 3.39, p = 0.0008

Step 8: Saving evaluation results...
  ✓ Saved to results/tables/ and results/forecasts/

✓ Forecast evaluation complete!
Next step: Run 07_cg_regression.R


✓ Phase 6 complete.

═══════════════════════════════════════════════════
  PHASE 7: COIBION-GORODNICHENKO REGRESSION
═══════════════════════════════════════════════════

=== Coibion-Gorodnichenko Regression Analysis ===

Step 1: Loading forecast results...
  ✓ Data loaded.

Step 2: Computing forecast revisions...
  Revision = F_{t+h|t} - F_{t+h|t-1}

  ✓ Forecast revisions computed.

Step 3: Merging forecast errors with revisions...
  CG dataset created: 215 observations

Step 4: Estimating CG regressions...
  Regression: (Actual - Forecast) = α + β × (Forecast_t - Forecast_{t-1}) + ε
  Using Newey-West HAC standard errors


═══ CG Regression Results (Small Model, CPI) ═══

 horizon        beta         se     t_stat    p_value n_obs
     h=1 -0.02801594 0.09365231 -0.2991484 0.76511851   215
     h=3 -0.46396692 0.15857024 -2.9259394 0.00380641   215
    h=12 -1.01756837 0.44639593 -2.2795198 0.02362671   215

Step 5: Interpretation of β coefficients:

h=1:
  β = -0.0280 (SE = 0.0937)
  95% CI: [-0.2116, 0.1555]
  → Not significantly different from 0 (rational expectations)

h=3:
  β = -0.4640 (SE = 0.1586)
  95% CI: [-0.7748, -0.1532]
  → β < 0: Over-reaction to news (diagnostic expectations)

h=12:
  β = -1.0176 (SE = 0.4464)
  95% CI: [-1.8925, -0.1426]
  → β < 0: Over-reaction to news (diagnostic expectations)

Step 6: Saving CG regression results...
  ✓ Saved to results/tables/ and results/forecasts/

═══════════════════════════════════════════════════
  CG REGRESSION ANALYSIS COMPLETE
═══════════════════════════════════════════════════

Key Findings (Small Model, CPI):
  h=1:  β = -0.0280 (p = 0.765)
  h=3:  β = -0.4640 (p = 0.004)
  h=12: β = -1.0176 (p = 0.024)

Next Steps:
  1. Repeat for Medium and Full models to compute Δβ
  2. Run 08_visualization.R to create figures
  3. Test hypothesis: Does sentiment move β toward negative?


✓ Phase 7 complete.

╔════════════════════════════════════════════════════════════════════╗
║                                                                    ║
║                  ANALYSIS PIPELINE COMPLETE                        ║
║                                                                    ║
╚════════════════════════════════════════════════════════════════════╝

Execution Summary:
  Start time: 2025-12-26 15:04:08
  End time: 2025-12-26 16:04:24
  Total elapsed time: 60.3 minutes

Output Files:
  Data:
    - data/processed/*.rds (estimation and evaluation data)
  Forecasts:
    - results/forecasts/*_model_forecasts.rds
    - results/forecasts/hyperparameters_evolution.csv
  Tables:
    - results/tables/rmsfe_results.csv
    - results/tables/relative_rmsfe.csv
    - results/tables/cg_regression_results.csv
  Diagnostics:
    - results/diagnostics/*.rds

Next Steps:
  1. Review results in results/tables/
  2. Create visualizations (08_visualization.R - TO BE IMPLEMENTED)
  3. Integrate findings into ForecastingHorseRace.tex

Log saved to: results/analysis_log_20251226_150408.txt 

